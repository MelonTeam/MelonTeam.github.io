<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>机器学习入门系列03，Error的来源：偏差和方差（bias 和 variance） | Melon Team</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="引用课程：http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML16.html

先看这里，可能由于你正在查看这个平台行间公式不支持很多的渲染，所以最好在我的CSDN上查看，传送门：（无奈脸）

CSDN博客文章地址：http://blog.csdn.net/zyq522376829/article/details/66611368

回顾第二篇中神奇宝贝的">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习入门系列03，Error的来源：偏差和方差（bias 和 variance）">
<meta property="og:url" content="http://melonteam.com/2017/03/27/ML03BiasAndVariance/index.html">
<meta property="og:site_name" content="Melon Team">
<meta property="og:description" content="引用课程：http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML16.html

先看这里，可能由于你正在查看这个平台行间公式不支持很多的渲染，所以最好在我的CSDN上查看，传送门：（无奈脸）

CSDN博客文章地址：http://blog.csdn.net/zyq522376829/article/details/66611368

回顾第二篇中神奇宝贝的">
<meta property="og:image" content="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fe0ofd7d2nj20vi0hsgnx.jpg">
<meta property="og:image" content="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fe0ofvddt0j20gi07uabz.jpg">
<meta property="og:image" content="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fe0ogcmj2dj20820let9d.jpg">
<meta property="og:image" content="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fe0ogsfqagj20d80kswf4.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fe0oh8rezxj20ea0ludgg.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fe0ohoz0lwj20z00swnkq.jpg">
<meta property="og:image" content="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fe0oi5o6ruj21320ggafm.jpg">
<meta property="og:image" content="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fe0oikto66j21260gytbv.jpg">
<meta property="og:image" content="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fe0oj04znij212k0scwqo.jpg">
<meta property="og:image" content="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fe0ojgrieaj212s0q6qem.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fe0ojw3h0aj210o0pytgs.jpg">
<meta property="og:image" content="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fe0oknilxvj213u0tak3p.jpg">
<meta property="og:image" content="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fe0ol56hmbj21340rw4bm.jpg">
<meta property="og:image" content="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fe0olkyjloj212q0q6n4k.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fe0om3bqn7j20g00aaaax.jpg">
<meta property="og:image" content="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fe0omjdtyuj213s0n2gw2.jpg">
<meta property="og:image" content="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fe0omyc6a1j210g0c875o.jpg">
<meta property="og:image" content="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fe0ondk0y0j21260l6q69.jpg">
<meta property="og:image" content="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fe0onviwy1j21200qmn08.jpg">
<meta property="og:updated_time" content="2017-03-28T07:44:53.466Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习入门系列03，Error的来源：偏差和方差（bias 和 variance）">
<meta name="twitter:description" content="引用课程：http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML16.html

先看这里，可能由于你正在查看这个平台行间公式不支持很多的渲染，所以最好在我的CSDN上查看，传送门：（无奈脸）

CSDN博客文章地址：http://blog.csdn.net/zyq522376829/article/details/66611368

回顾第二篇中神奇宝贝的">
<meta name="twitter:image" content="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fe0ofd7d2nj20vi0hsgnx.jpg">
  
    <link rel="alternate" href="/atom.xml" title="Melon Team" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Melon Team</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://melonteam.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-ML03BiasAndVariance" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/03/27/ML03BiasAndVariance/" class="article-date">
  <time datetime="2017-03-27T02:03:33.000Z" itemprop="datePublished">2017-03-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      机器学习入门系列03，Error的来源：偏差和方差（bias 和 variance）
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>引用课程：<a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML16.html" target="_blank" rel="external">http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML16.html</a></p>
</blockquote>
<p>先看这里，可能由于你正在查看这个平台行间公式不支持很多的渲染，所以最好在我的CSDN上查看，传送门：（无奈脸）</p>
<blockquote>
<p>CSDN博客文章地址：<a href="http://blog.csdn.net/zyq522376829/article/details/66611368" target="_blank" rel="external">http://blog.csdn.net/zyq522376829/article/details/66611368</a></p>
</blockquote>
<h1 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h1><p>第二篇中神奇宝贝的例子：</p>
<a id="more"></a>
<p><img src="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fe0ofd7d2nj20vi0hsgnx.jpg" alt=""></p>
<p>可以看出越复杂的model 再测试集上的性能并不是越好</p>
<p>这篇要讨论的就是 error 来自什么地方？</p>
<p>error主要的来源有两个，bias（偏差） 和 variance（方差）</p>
<h1 id="估测"><a href="#估测" class="headerlink" title="估测"></a>估测</h1><p><img src="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fe0ofvddt0j20gi07uabz.jpg" alt=""></p>
<p>假设上图为神奇宝贝cp值的真正方程，当然这只有Niantic（制作《Pokemon Go》的游戏公司）知道。从训练集中可以找到真实方程$\hat{f}$ 的近似方程 $f^{*}$。</p>
<h2 id="估测bias-和-variance"><a href="#估测bias-和-variance" class="headerlink" title="估测bias 和 variance"></a>估测bias 和 variance</h2><h3 id="估测变量-x-的平均值"><a href="#估测变量-x-的平均值" class="headerlink" title="估测变量 $x$ 的平均值"></a>估测变量 $x$ 的平均值</h3><ul>
<li>假设$x$的平均值为 $\mu$，方差为 $\sigma^{2}$</li>
</ul>
<p>估测平均值怎么做呢？</p>
<ul>
<li>首先拿到N个样品点：${x^{1}, x^{2}, \ldots, x^{N}}$</li>
<li>计算平均值得到$m$, $m = \frac{1}{N} \sum_{n} x^{n} \neq \mu$</li>
</ul>
<p><img src="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fe0ogcmj2dj20820let9d.jpg" alt=""></p>
<p>但是如果计算很多组的m ，然后求m的期望</p>
<p>$$<br>E[m] = E[\frac{1}{N} \sum<em>{n} x^{n}] = \frac{1}{N}\sum</em>{n}E[x^{n}] = \mu<br>$$</p>
<p>这个估计呢是无偏估计（unbiased）。</p>
<p>然后m分布对于 $\mu$ 的离散程度（方差）：</p>
<p>$$<br>Var[m] = \frac{\sigma^{2}}{N}<br>$$</p>
<p>这主要取决于N，下图可看出N越小越离散</p>
<p><img src="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fe0ogsfqagj20d80kswf4.jpg" alt=""></p>
<h3 id="估测变量-x-的方差"><a href="#估测变量-x-的方差" class="headerlink" title="估测变量 $x$ 的方差"></a>估测变量 $x$ 的方差</h3><p>首先用刚才的方法估测m，</p>
<p>$$<br>m = \frac{1}{N} \sum_{n} x^{n} \neq \mu<br>$$</p>
<p>然后再做下面计算：</p>
<p>$$<br>s^{2} = \frac{1}{N} \sum_{n}(x^{n} - m)^{2}<br>$$</p>
<p>就可以用$s^{2}$来估测  $\sigma^{2}$</p>
<p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fe0oh8rezxj20ea0ludgg.jpg" alt=""></p>
<p>这个估计是有偏估计（biased）,</p>
<p>求 $s^{2}$的期望值：</p>
<p>$$<br>E[s^{2}] = \frac{N - 1}{N} \sigma^{2} \neq \sigma^{2}<br>$$</p>
<p>用靶心来说明一下bias和variance的影响</p>
<p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fe0ohoz0lwj20z00swnkq.jpg" alt=""></p>
<p>靶心为真正的方程 $\hat{f}$ ，深蓝色点为$f^{<em>}$ ，是实验求得的方程。求$f^{</em>}$的期望值$\bar{f} = E[f^{*}]$，即图中浅蓝色的点。</p>
<p>$\bar{f}$ 和 $\hat{f}$之间的距离就是误差 bias，而$\bar{f}$ 和 $f^{*}$ 之间的距离就是误差 variance。4幅图的对比观察两个误差的影响。</p>
<p>bias就是射击时瞄准的误差，本来应该是瞄准靶心，但bias就造成瞄准准心的误差；而variance就是虽然瞄准在 $\bar{f}$，但是射不准，总是射在 $\bar{f}$ 的周围。</p>
<h2 id="为什么会有很多的-f"><a href="#为什么会有很多的-f" class="headerlink" title="为什么会有很多的 $f^{*}$?"></a>为什么会有很多的 $f^{*}$?</h2><p>讨论系列02中的案例：这里假设是在平行宇宙中，抓了不同的神奇宝贝</p>
<p><img src="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fe0oi5o6ruj21320ggafm.jpg" alt=""></p>
<p>用同一个model，在不同的训练集中找到的 $f^{*}$就是不一样的</p>
<p><img src="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fe0oikto66j21260gytbv.jpg" alt=""></p>
<p>这就像在靶心上射击，进行了很多组（一组多次）。现在需要知道它的散布是怎样的，将100个宇宙中的model画出来</p>
<p><img src="http://wx1.sinaimg.cn/mw690/a9c4d5f6gy1fe0oj04znij212k0scwqo.jpg" alt=""></p>
<p>不同的数据集之前什么都有可能发生—||</p>
<h3 id="考虑不同model的variance"><a href="#考虑不同model的variance" class="headerlink" title="考虑不同model的variance"></a>考虑不同model的variance</h3><p><img src="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fe0ojgrieaj212s0q6qem.jpg" alt=""></p>
<p>一次model的variance就比较小的，也就是是比较集中，离散程度较小。而5次model 的 variance就比较大，同理散布比较广，离散程度较大。</p>
<p>所以用比较简单的model，variance是比较小的（就像射击的时候每次的时候，每次射击的设置都集中在一个比较小的区域内）。如果用了复杂的model，variance就很大，散布比较开。</p>
<p>这也是因为简单的model受到不同训练集的影响是比较小的。</p>
<h3 id="考虑不同model的-bias"><a href="#考虑不同model的-bias" class="headerlink" title="考虑不同model的 bias"></a>考虑不同model的 bias</h3><p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fe0ojw3h0aj210o0pytgs.jpg" alt=""></p>
<p>这里没办法知道真正的 $\hat{f}$，所以假设图中的那条黑色曲线为真正的 $\hat{f}$</p>
<p><img src="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fe0oknilxvj213u0tak3p.jpg" alt=""></p>
<p>结果可视化，一次平均的 $\bar{f}$没有5次的好，虽然5次的整体结果离散程度很高。</p>
<p><img src="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fe0ol56hmbj21340rw4bm.jpg" alt=""></p>
<p>一次model的bias比较大，而复杂的5次model，bias就比较小。</p>
<p>直观的解释：简单的model函数集的space比较小，所以可能space里面就没有包含靶心，肯定射不中。而复杂的model函数集的space比较大，可能就包含的靶心，只是没有办法找到确切的靶心在哪，但足够多的，就可能得到真正的 $\bar{f}$。</p>
<h3 id="bias-v-s-variance"><a href="#bias-v-s-variance" class="headerlink" title="bias v.s. variance"></a>bias v.s. variance</h3><p><img src="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fe0olkyjloj212q0q6n4k.jpg" alt=""></p>
<p>将系列02中的误差拆分为bias何variance。简单model（左边）是bias比较大造成的error，这种情况叫做 <strong>Underfitting（欠拟合）</strong>，而复杂model（右边）是variance过大造成的error，这种情况叫做<strong>Overfitting（过拟合）</strong>。</p>
<h1 id="怎么判断？"><a href="#怎么判断？" class="headerlink" title="怎么判断？"></a>怎么判断？</h1><h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fe0om3bqn7j20g00aaaax.jpg" alt=""></p>
<ul>
<li>如果model没有很好的fit训练集，就是bias过大，也就是Underfitting</li>
<li>如果model很好的fit训练集，即再训练集上得到很小的error，但在测试集上得到大的error，这意味着model可能是variance比较大，就是Overfitting。</li>
</ul>
<p>对于Underfitting和Overfitting，是用不同的方式来处理的</p>
<h3 id="bias大，Underfitting"><a href="#bias大，Underfitting" class="headerlink" title="bias大，Underfitting"></a>bias大，Underfitting</h3><p>此时应该重新设计model。因为之前的函数集里面可能根本没有包含$\hat{f}$。可以：</p>
<ul>
<li>将更多的feature加进去，比如考虑高度重量，或者HP值等等。</li>
<li>或者考虑更多次幂、更复杂的model。</li>
</ul>
<p>如果此时强行再收集更多的data去训练，这是没有什么帮助的，因为设计的函数集本身就不好，再找更多的训练集也不会更好。</p>
<h3 id="variance大，Overfitting"><a href="#variance大，Overfitting" class="headerlink" title="variance大，Overfitting"></a>variance大，Overfitting</h3><p>简单粗暴的方法：More data</p>
<p><img src="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fe0omjdtyuj213s0n2gw2.jpg" alt=""></p>
<p>但是很多时候不一定能做到收集更多的data。可以针对对问题的理解对数据集做调整（Regularization）。比如识别手写数字的时候，偏转角度的数据集不够，那就将正常的数据集左转15度，右转15度，类似这样的处理。</p>
<h1 id="选择model"><a href="#选择model" class="headerlink" title="选择model"></a>选择model</h1><ul>
<li>现在在bias和variance之间就需要一个权衡</li>
<li>想选择的model，可以平衡bias和variance产生的error，使得总error最小</li>
<li>但是下面这件事最好不要做：</li>
</ul>
<p><img src="http://wx2.sinaimg.cn/mw690/a9c4d5f6gy1fe0omyc6a1j210g0c875o.jpg" alt=""></p>
<p>用训练集训练不同的model，然后在测试集上比较error，model3的error比较小，就认为model3好。但实际上这只是你手上的测试集，真正完整的测试集并没有。比如在已有的测试集上error是0.5，但有条件收集到更多的测试集后通常得到的error都是大于0.5的。</p>
<h2 id="Cross-Validation（交叉验证）"><a href="#Cross-Validation（交叉验证）" class="headerlink" title="Cross Validation（交叉验证）"></a>Cross Validation（交叉验证）</h2><p><img src="http://wx4.sinaimg.cn/mw690/a9c4d5f6gy1fe0ondk0y0j21260l6q69.jpg" alt=""></p>
<p>图中public的测试集是已有的，private是没有的，不知道的。Cross Validation 就是将训练集再分为两部分，一部分作为训练集，一部分作为验证集。用训练集训练model，然后再验证集上比较，确实出最好的model之后（比如model3），再用全部的训练集训练model3，然后再用public的测试集进行测试，此时一般得到的error都是大一些的。不过此时会比较想再回去调一下参数，调整model，让在public的测试集上更好，但不太推荐这样。（心里难受啊，大学数模的时候就回去调，来回痛苦折腾）</p>
<p>上述方法可能会担心将训练集拆分的时候分的效果比较差怎么办，可以用下面的方法。</p>
<h2 id="N-fold-Cross-Validation（N-折交叉验证）"><a href="#N-fold-Cross-Validation（N-折交叉验证）" class="headerlink" title="N-fold Cross Validation（N-折交叉验证）"></a>N-fold Cross Validation（N-折交叉验证）</h2><p>将训练集分成N份，比如分成3份。</p>
<p><img src="http://wx3.sinaimg.cn/mw690/a9c4d5f6gy1fe0onviwy1j21200qmn08.jpg" alt=""></p>
<p>比如在三份中训练结果Average Error是model1最好，再用全部训练集训练model1。（貌似数模也干过，当年都是莫名其妙的分，想想当年数模的时候都根本来不及看是为什么，就是一股脑上去做00oo00）</p>
<blockquote>
<p>新博客地址：<a href="http://yoferzhang.com/post/20170327ML03BiasAndVariance" target="_blank" rel="external">http://yoferzhang.com/post/20170327ML03BiasAndVariance</a></p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://melonteam.com/2017/03/27/ML03BiasAndVariance/" data-id="cj0ur8cbs0007so1u9jmav69r" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/03/27/ML04GradientDescent/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          机器学习入门系列04，Gradient Descent（梯度下降法）
        
      </div>
    </a>
  
  
    <a href="/2017/03/27/ML02Regression/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">机器学习入门系列02，Regression 回归：案例研究</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Android/">Android</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/IM/">IM</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/IOS/">IOS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/我说/">我说</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/视频/">视频</a></li></ul>
    </div>
  </div>


  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">三月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">一月 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/03/28/Deep_learning_entry_2/">深度学习入门实战（二）</a>
          </li>
        
          <li>
            <a href="/2017/03/28/Deep_learning_entry_1/">深度学习入门实战（一）</a>
          </li>
        
          <li>
            <a href="/2017/03/27/Video_codec_learning_sharing/">视频编解码学习分享</a>
          </li>
        
          <li>
            <a href="/2017/03/27/IOS_touch_event_distribution_mechanism/">IOS触摸事件分发机制详解</a>
          </li>
        
          <li>
            <a href="/2017/03/27/Android_short_video_side_of_the_next_sowing_solution/">Android短视频边下边播详解</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 Melon Team<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>