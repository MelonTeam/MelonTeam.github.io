---
layout: post
title: "一种用于短文本的神经响应机"
date: 2017-08-31 19:35:00 +0800
categories: 其他
author: yockieyang
tags: 机器学习短语回复
---

* content
{:toc}

| 导语 这篇文章是翻译别人的，来源是https://arxiv.org/abs/1503.02364

**摘要**  
我们提出了神经响应机（NRM），一种基于神经网络的响应用于短文本的方法。NRM采用通用的编码器-
解码器框架：他通过输入文本的潜在特征形成的响应代作为响应的解码过程，而编码和解码都是用复现神经网络（RNN）实现的。NRM通过微博服务器收集的大量单向对话进行训练。实证研究表明，NRM可以为超过75％的输入文本生成语法正确和内容适当的响应，在同样的设置中超越了最先进的技术，包括基于检索和基于SMT的模型。  
<!--more-->
**1\. 引言**  
自然语言交谈是人类智能问题中最具挑战性的问题之一，涉及语言理解，推理和常识知识的利用。以前在这个方向上的工作主要集中在基于规则或学习方法上（Williams和Young，2007;
Schatzmann et al。，2006; Misu et al。，2012; Litman et
al。，2000）。这些类型的方法通常依赖于手工设计规则或使用特定学习算法和少量数据对模型进行自动训练，这使得难以开发可扩展的开放域会话系统。  
最近由于Twitter1和微博等微博服务的爆炸性增长，网络上可用的会话数据量大大增加。这使得数据驱动的方法能够处理相应对话问题（Ji et
al。，2014; Ritter et
al。，2011）。短语对话（简称STC）并不是多次谈话，而是简称短文对话（STC），只考虑了一轮对话，每轮都由两条短文组成，前者为
来自用户的输入（称为post），后者由计算机给出的响应。对STC的研究可以揭示对自然语言对话的复杂机制。  
STC的以前的方法分为两类：1）基于检索的方法（Ji et
al。，2014）和2）基于统计机器翻译（SMT）的方法（Ritter等，2011）。基于检索的方法的基本思想是通过用各种匹配特征（例如共享字的数量）的线性或非线性组合对候选响应进行排名来选择合适的响应。基于检索的方法的主要缺点如下：

  1. 响应是预先存在的，并且难以根据任务的特定文本或要求定制，例如风格或态度。
  2. 即使在耗时的特征工程之后，单独使用匹配特征通常也不足以区分正面响应与负面响应。 （例如，由于不匹配的命名实体造成的惩罚难以纳入模型）  
另一方面，基于SMT的方法是生成的。
基本上，它将响应生成视为翻译问题，其中模型被训练在并行的后响应部分。尽管它具有生成性，但该方法本质上不适用于响应生成，因为响应与翻译问题并不是语义上相当的。实际上，一个帖子可以收到完全不同内容的回复，如下图中的示例所示：  

![](/image/yi_zhong_yong_yu_duan_wen_ben_de_shen_jing_xiang_ying_ji/1b3e49147ffe6a3745d5730f5cfee21e280609ed52c1fd6e81a7e26c6f4cd510)

  
**1.1概述**  
在本文中，我们采用概率模型来解决响应生成问题，并提出使用神经编码器解码器进行此任务，称为神经响应机（NRM）。如图1所示，神经编码器 -
解码器模型首先将该帖子总结为向量表示，然后将该表示传到解码器以产生响应。我们进一步推广这个方案，以便在生成过程中，遵循（Bahdanau等人，2014）最初提出用于基于神经网络的机器翻译与自动对准的想法，使得后期表示可以动态地改变。  

![](/image/yi_zhong_yong_yu_duan_wen_ben_de_shen_jing_xiang_ying_ji/86b2cd8e07e6a39892cbbe99fed88e613d4e514dc3dfa949177e4b72d7019145)

  
图1：编码器 - 解码器框架的自动响应生成图  
NRM估计了给予文本的回复的可能性。
显然，这个估计应该足够复杂以表示所有合适的响应。类似的框架已被用于机器翻译，取得了显着的成功（Kalchbrenner和Blunsom，2013;
Auli等，2013; Sutskever等，2014;
Bahdanau等，2014）。请注意，在机器翻译中的任务和估计目标语言句子对源语言句子的概念具有相同的含义，这比我们在这里考虑的STC任务要容易得多。在本文中，我们证明，NRM在配备合理数量的数据时，可以为STC提供满意的响应估计（因此响应发生器），尽管任务困难。  
我们的主要贡献是双重的：1）我们建议使用基于编码器 - 解码器的神经网络在STC中产生响应;
2）我们实验证实，当采用合理数量的数据训练时，提出的方法可以比传统的基于检索和基于翻译的方法获得更好的表现。  
**1.2章节简介**  
在本文的接下来的部分，我们首先在第2节中介绍STC的数据集。然后，我们详细介绍了第3节中NRM的模型，其次是第4节中的培训细节。之后，我们报告了实验结果。在第6节中，我们做相应的总结。  
**2\. STC的数据集**  
我们的模型受到来自微博3的约440万双对话的语料库的训练。  
**2.1新浪微博对话**  
微博是中国流行的类似Twitter的微博服务，用户可以在其上发布短消息（简称本文提醒），向公众或其他用户发送。其他用户对已发布的帖子发表评论，这将被称为响应。
就像Twitter一样，微博的帖子和回应的长度限制为140个汉字，使得后响应对成为短文对话的理想替代品。  

![](/image/yi_zhong_yong_yu_duan_wen_ben_de_shen_jing_xiang_ying_ji/0f69ab8acc2c2866297b506936427dc6c76cf079749c536cdeabae129becaf6d)

  
表1：数据集的一些统计数据。 标签数据集和精细调谐分别用于基于检索的方法学习排序和基于SMT的微调方法。  
**2.2数据集描述**  
为了构建这个百万级别的数据集，我们首先抓取数亿个响应对，然后按照（Wang等人，2013）中提出的类似方式清理原始数据，包括1）删除像“哇
“，2）过滤出潜在的广告，以及3）删除前30个之后的响应，以实现主题一致性。表1显示了本工作中使用的数据集的一些统计信息。
可以看出，每个帖子平均有20个不同的答案。除了样本和其响应之间的语义差距之外，这是用于传统翻译的通用并行数据集的另一个关键区别。  
**3 .STC的神经响应机**  
NRM的基本思想是通过构建一个帖子的隐藏表示，然后根据它生成响应，如图2所示。  

![](/image/yi_zhong_yong_yu_duan_wen_ben_de_shen_jing_xiang_ying_ji/11241ff78ae5d151a43b368b125853da12743af7c01f51fb7b83a6c574a19cca)

  
图2：基于编码器解码器的NRM的一般框架和数据流  
在具体的说明中，编码器将输入序列x =（x1，…，xT）转换为一组高维隐藏表示h =（h1，…，hT），其与注意信号
在时间t（表示为αt）被馈送到上下文发生器以在时间t（表示为ct）构建到解码器的上下文输入。
然后ct由矩阵L（作为解码器的一部分）线性变换成产生RNN的刺激，以产生第t个响应词（表示为yt）。  
在神经翻译系统中，L将源语言的表示转换为目标语言。在NRM中，L扮演着更为困难的角色：需要将帖子（或其中的一部分）的表现转化为许多合理的响应的丰富特征。有点令人惊讶的是，这可以通过在第5.3节中验证的“表示空间”中的线性转换来达到一个合理的水平，我们显示一个帖子实际上可以从NRM中调用许多不同的响应。  
注意信号的作用是确定在生成过程中哪个部分的隐藏特征h应该被放大。应该注意的是，αt可以随着时间的推移而变化，或者在生成响应序列y时动态变化。
在动态设置中，αt可以是历史生成的子序列（y1，…，yt-1），输入序列x或其潜在表示的函数，更多细节将在后面的3.2节中给出。  
我们使用经编神经网络（RNN）作为编码器和解码器，其自然能力总结和生成任意长度的字序列（Mikolov等，2010; Sutskever等，2014;
Cho等，2014）。  

![](/image/yi_zhong_yong_yu_duan_wen_ben_de_shen_jing_xiang_ying_ji/1c758e57ff0835ecdec79ee075e6d80125d87d2cda429d667a9bcb8bdec583cd)

  
图3：RNN解码器的图形模型。 虚线表示与函数g（·）相关的变量，实线表示与函数f（·）有关的变量。  
**3.1解码器中的计算**  
图3给出了解码器的图形模型，其基本上是标准的RNN语言模型，除了基于上下文输入c。第t个字的生成概率由下式计算  

![](/image/yi_zhong_yong_yu_duan_wen_ben_de_shen_jing_xiang_ying_ji/b262303a20ada960f8afc445068ab29184cd3487daf93b27b6b101dc91bf614a)

  
其中yt是一个单词表示，g（·）是softmax激活函数，st是隐藏状态在时间t的解码器计算  

![](/image/yi_zhong_yong_yu_duan_wen_ben_de_shen_jing_xiang_ying_ji/30a33931e5c102620a45cdc93600ac77e49a87def051bbd9a0b0712434309ae5)

  
f（·）是非线性激活函数，变换L通常被分配为f（·）的参数。这里f（·）可以是逻辑函数，复杂的长期短期记忆（LSTM）单元（Hochreiter和Schmidhuber，1997）或最近提出的门控循环单元（GRU）（Chung等，2014;
Cho等，2014）。与“非门”逻辑功能相比，LSTM和GRU专为其长期记忆而设计：可以在延长的时间步长下存储信息，而无需太多的衰减。我们在这项工作中使用GRU，因为它更适合在LSTM在序列建模方面进行比较（Chung等，2014），而且参数较少，训练更容易。  
**3.2编码器中的计算**  
我们考虑三种类型的编码方案，即1）全局方案，2）局部方案，以及组合1）和2）的混合方案。  
**全局方案**：图4示出了用于全局编码方案的RNN编码器和相关上下文生成器的图形模型。时间t的隐藏状态由计算（即GRU单元），并且通过简单的上下文生成操作，我们基本上使用最终隐藏状态hT作为句子的全局表示。然而，这个方案有其缺点：整个帖子的矢量总结通常很难获得，并可能失去响应生成的重要细节，特别是当隐藏状态的维度不够大时4。在本文中，具有这种全局编码方案的NRM被称为NRM-glo。  

![](/image/yi_zhong_yong_yu_duan_wen_ben_de_shen_jing_xiang_ying_ji/34664e5f78a8cbec9ed48ef56da3cf4ad4815bddfced3c230c1da2ecafcac427)

  
图4：NRM-glo中编码器的图形模型，其中最后一个隐藏状态用作上下文向量。  
**局部方案：**最近，Bahdanau et al（2014）和Graves（2013）引入了一种注意机制，允许解码器动态选择和线性组合输入序列的不同部分，其中加权因子αtj决定应选择哪个部分生成新的词yt，它又是隐藏状态的函数，如图5所示。基本上，注意机制αtj对位置j之间的输入和位置t处的输出之间的对准建模，因此可以被视为局部匹配模型。局部方案是在（Bahdanau等人，2014年）中设计的，用于在源语句和机器翻译中的部分目标句子之间自动对齐。该方案具有根据生成的响应词自适应地集中在输入文本的一些重要词上的优点。该本地编码方案的NRM被称为NRM-loc。  

![](/image/yi_zhong_yong_yu_duan_wen_ben_de_shen_jing_xiang_ying_ji/0c3699afb05d0bad2d84a3f5ad89fbc0ec33f53164c572391fd9851e4e32a1d5)

  
图5：NRM-loc中编码器的图形模型，其中隐藏状态的加权和用作上下文向量。  
**3.3扩展：局部和全局模型的组合**  
在STC的任务中，NRM-glo对整个样本进行了总结，而NRM-
loc可以自适应地选择样本中的重要词来进行各种适当的回应。因为STC中的后响应对不是严格平行的，并且不同上下文中的一个词可以具有不同的含义，我们推测NRM-
glo中的全局表示可以为提取局部上下文提供有用的上下文，因此与NRM-
同上。因此，通过连接其编码的隐藏状态以形成每个时间戳的扩展隐藏表示来组合两个模型是自然的延伸，如图6所示。我们可以看到总结被并入和，为本地匹配提供了一个全局上下文。通过这种混合方式，我们希望将本地和全球信息都引入到响应的产生中。
具有该上下文生成机制的模型被表示为NRM-hyb。  
应该注意的是，NRM-hyb中的上下文生成器将引入全局编码器和局部编码器中的不同编码机制，尽管它们将在以后的组合中形成统一的表示。更具体地说，NRM-
glo的最后一个隐藏状态起到与NRM-loc最后一个状态不同的作用，因为它有责任对整个输入句进行编码。然而，当从头开始学习两个编码RNN的参数时，NRM-
glo的这个作用往往在训练混合编码器时不被充分强调。为此，我们使用以下技巧：我们首先用NRM-loc和NRM-glo的参数初始化NRM-
hyb，然后对编码器中的参数进行微调并对解码器的参数进行训练。  

![](/image/yi_zhong_yong_yu_duan_wen_ben_de_shen_jing_xiang_ying_ji/39cf32c9c8514eb54626fb6f4e4951d72539ec9157c01a82b836c22e5630f3d8)

  
图6：NRM-hyb中编码器的图形模型，而上下文生成函数为，这里[]表示向量和的级联  
为了学习模型的参数，我们最大限度地发挥在训练集中观察原始响应的可能性。对于新的帖子，NRM通过使用波束大小= 10的从左到右的波束搜索来生成其响应。  
**4实验**  
我们评估了第3节描述的NRM-glo，NRM-loc和NRM-hyb中描述的NRM的三种不同设置，并将其与基于检索和基于SMT的方法进行比较。  
**4.1实施细则**  
我们使用斯坦福大学汉语分词器将帖子和回答分成单词。
虽然这两个帖子和回答都是用相同的语言写的，但是两个单词集合的分布是不同的：帖子的单词集合中有125,237个单词，而答复文本的单词集合中有679,958个单词。因此，我们通过在每一方使用40,000个最常见的词来构建两个单独的词汇和答复词汇，分别占97.8％的词语和96.2％的答案。所有剩下的单词都被一个特殊的令牌“UNK”所取代。编码器和解码器的隐藏状态的尺寸均为1,000，后置和响应的字嵌入尺寸均为620。  
模型参数通过从-0.1和0.1之间的均匀分布进行随机采样来初始化。我们所有的模型都小批量使用随机梯度下降算法在NVIDIA Tesla K40
GPU上进行了培训。 每个模型的训练阶段花了两个星期。  
**4.2竞争对手模型**  
**检索为主：**基于检索的模型，对于任何给定的样本p _，响r _从大型的后响应（p，r）仓库中检索。这些模型依赖于三个关键组件：大型存储库，特征函数集Φi（p _，（p，r））以及机器学习模型来组合这些特征。在这项工作中，整个440万个微博对被用作存储库，14个特征，从简单余弦相似性到一些深度匹配模型（Ji et al。，2014）用于确定一个帖子对给定帖子的适用性 p _通过以下线性模型  

![](/image/yi_zhong_yong_yu_duan_wen_ben_de_shen_jing_xiang_ying_ji/d83ff2fe526e12139a77e7874e48f19056ee080d2a822ca985d3bfab96060bdf)

  
按照（Ji et
al。，2014）的排名策略，我们从4.4M版本库中选出225个帖子，并从基线检索器6中提取了大约30个回复，并手动标记它们以获得标记为6,017个后响应对。我们使用基于标记数据集的参数ωi的排名SVM模型（Joachims，2006）。
与NRM相比，在评估过程中只考虑了最高的响应。  
**基于SMT：**在基于SMT的模型中，后响应对直接用作训练翻译模型的并行数据。我们使用最广泛使用的基于开源短语的翻译模型 - 摩西（Koehn等，2007）。由3000个后响应对组成的另一个并行数据用于调整系统。在（Ritter等人，2011）中，作者使用修改后的SMT模型来获得Twitter“刺激”的“响应”。 主要修改是用新的短语对选择方法替换标准GIZA ++字对齐模型（Och和Ney，2003），其中考虑训练数据中的所有可能的短语对，并且其相关概率由 Fisher精确测试，其性能略好于默认设置。与基于检索的方法相比，基于SMT的方法产生的响应通常具有流畅性或甚至语法问题较少。在这项工作中，我们选择默认设置的摩西作为我们的SMT模型。  
**5结果与分析**  
响应生成的自动评估仍然是一个开放的问题。 广泛接受的翻译评估方法（例如BLUE分数（Papineni et
al。，2002））不适用，因为适当的反应范围如此之大，实际上不可能给予足够的覆盖。在统计语言建模中，通常使用的测量方法是“复杂性”（Perplexity）评估也是不合理的，因为响应的自然性和与后期的相关性无法得到很好的评估。因此，我们诉诸于人类的判断，类似于（Ritter
et al。，2011），但具有重要的区别。  
**5.1评估方法**  
我们采用人为注释来比较不同型号的性能。
邀请到具有至少3年新浪微博经验的五名贴标人进行人为评估。从五个评估模型获得的响应被合并，并为每个贴标人随机排列。指示标签者被设想为他们是原始帖子的作者，并判断一个响应（生成或检索）是否适合于输入文章。分数为0到2的响应分为三个等级：  

![](/image/yi_zhong_yong_yu_duan_wen_ben_de_shen_jing_xiang_ying_ji/041380cd82b3c747b3b5b9fbbe22c102b5c22fc390a42a92d0d7761ca90c72d7)

  
图7：一个示例帖子及其五个人为注释的候选响应。 帖子的内容意味着足球比赛已经开始，而Response1的作者还在等待比赛开始。
Response2谈论了意大利的食物。
Response3是一个广泛使用的响应，但它适合这个样本。Response4表示当前分数仍为0：0，仅在此具体情况下才适用。  

![](/image/yi_zhong_yong_yu_duan_wen_ben_de_shen_jing_xiang_ying_ji/a64a65f71b2ab0a0e9af7d96d3a396054591de8212bdc6fff5be5117a8bac4c1)

  
图8：不同模型产生的一些响应（原文为英文，用英文翻译），粗体字是实体名称  
**•适合（+2）：**回应显然是对职位的适当和自然回应;  
•**中性（+1）：**响应可以在特定场景中作出适当的响应;  
•**不合适（0）：**很难或不可能找到适合的响应场景。  
为了使注解任务可操作，生成响应的适用性可以从以下五个标准来判断：  
**（a） 语法和语义通畅：**回应应该是自然语言，没有任何语言通畅或语法的错误;  
**（b） 逻辑一致性：**答复在逻辑上应与测试样本一致;  
**（c） 语义相关性：**回应应与测试样本语义相关;  
**（d） 情景依赖：**回应可以取决于具体情况，但不应与前三个标准相抵触;  
**（e） 普遍性：**回应可以是一般性的，但不应与前三个标准相抵触;  
如果前三个条件（a），（b）和（c）中的任何一个是矛盾的，则所生成的响应应标记为“不合适”。一般或适合在特定情况下发布的回复应标注为“中性”。图7显示了一个帖子的标签结果及其响应的示例。
由于逻辑一致性和语义相关性错误，前两个响应被标记为“不合适”。Response4取决于场景（即当前分数为0：0），因此注释为“中性”。  

![](/image/yi_zhong_yong_yu_duan_wen_ben_de_shen_jing_xiang_ying_ji/9a3b3bb42f407156c0152f2c70bd170401ef97ac9828c82365ba25a0bc1bb497)

  
表3：成对模型比较的Friedman检验的p值和平均排名。 （基于Rtr.意味着基于检索的方法）  
**5.2 结论**  
我们的测试套件包含110个不出现在培训套件中的帖子，长度在6到22个汉语单词和12.5个单词之间。基于人为注释的实验结果总结在表2中，由三个类别的比例和每个模型的五个标签商之间的协议组成。除了基于SMT的模式，所有其他模式的协议价值在0.2到0.4的范围内，应被解释为“公平协议”。基于SMT的模型具有相对较高的kappa值0.448，大于0.4并被认为是“中等协议”，因为SMT产生的响应通常具有流畅性和语法错误，因此可以轻松达成协议
不合适的情况。  
从表2可以看出，SMT方法的性能比基于检索和NRM模型差得多，74.4％的生成响应被标记为不合适，主要是由于流畅性和相关性错误。这一观察结果证实了我们的直觉，STC数据集，其中一个可能对应于许多响应的帖子不能被简单地称为SMT模型中的平行语料库。  
令人惊讶的是，所有三个NRM产生的响应中，超过60％的回应被标记为“适用”或“中性”，这意味着大多数生成的响应与流畅和语义上相关。 在所有NRM变体中  
•NRM-loc优于NRM-
glo，表明动态生成的上下文可能比整个帖子的“静态”固定长度向量更有效，这与（Bahdanau等人，2014年）中的观察结果一致;  
•NRM-hyp优于NRM-loc和NRM-glo，表明post的全局表示是动态生成的本地上下文的补充。  
基于检索的模型具有与NRM-
glo相似的平均得分，其在中性条件下的比例优于所有其他方法。这是因为1）由基于检索的方法检索的响应实际上是由人类编写的，所以它们不会受到语法和流畅问题的困扰，2）各种功能函数的组合可能会确保所选择的响应与测试结果语义相关。然而，所选择的响应不是针对新的测试点定制的，所以合适的情况的比例低于三个神经生成模型。  
为了测试统计学意义，我们使用Friedman测试（Howell，2010），这是基于排名的几个相关样本的差异的非参数测试。表3显示了不同方法之间的比较的所有注释的平均排名和相应的p值
。基于检索和NRM-glo的比较并不重要，它们的排名差异很小。这表明基于检索的方法与NRM-glo方法相当。 NRM-
hyb优于所有其他方法，差异具有统计学意义（p <0.05）。NRM-loc和基于检索的方法的差异是微不足道的（p = 0.062）。
SMT比基于检索和NRM-hyb方法差得多。  
**5.3案例研究**  
图8显示了由我们的NRM产生的一些示例响应（仅给出最大可能性的那些）和可比较的基于检索的模型。有趣的是注意到，三个NRM变体提供了合适但相当独特的反应，具有不同的观点和词汇选择。这是我们推测的，是由模型之间的架构变化以及随机效应（如参数初始化）的变化引起的。另一个有趣的观察是在第四例中，其中基于检索的方法返回具有不匹配的实体名称“WenShan”的响应，这实际上是基于检索的模型的相当常见的问题，其中不一致的细节（例如，
日期，命名实体），这通常使得响应不合适，不能在检索响应中使用的匹配函数中被充分考虑。相比之下，我们观察到，NRM倾向于作出一般反应，几乎不产生这些细节。  

![](/image/yi_zhong_yong_yu_duan_wen_ben_de_shen_jing_xiang_ying_ji/c64dabe67787744428516eedf725f6ebcb7258ab60c5d4a50c3ce4bd0876dd68)

  
图9：由NRM-hyb生成的多个响应。  
我们也以NRM-
hyb为例来研究NRM生成多个响应的能力。图9列出了对同一个帖子的5个响应，这些响应是在大小为500的集合中搜索得到的，其中我们保持每个第一个单词最好的（最大的可能性）。可以看出，响应流畅，与样本相关，并且仍然有很大的不同，证实了我们最初的猜想，即NRM在用大而丰富的训练语料库推动时，可以作为一个可以覆盖很多
模式的密度估计。  
**6结论和未来工作**  
在本文中，我们探索了使用基于编码器解码器的神经网络系统，创建名称为神经响应机，以产生对一个帖子的响应。
实证研究证实，新提出的NRMs，特别是混合编码方案，可以超过最先进的基于检索和基于SMT的方法。我们的初步研究还表明，NRM可以为给定的帖子产生多种响应。
在未来的工作中，我们将考虑将用户的意图（或情绪）作为解码器的外部信号来生成具有特定目标的响应。

